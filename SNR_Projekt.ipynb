{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of SNR-Projekt.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN/XwlP8aCNTf9q7XZbU29J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Oichii/CosmeticsScan/blob/master/SNR_Projekt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vP6ZvXMlkbmU",
        "colab_type": "text"
      },
      "source": [
        "# Comparison of two deep convolutional neural networks architectures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKYd7roukIgv",
        "colab_type": "code",
        "outputId": "c77d591c-a64d-44a8-effb-882138512aa5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        }
      },
      "source": [
        "import keras\n",
        "from keras.applications import ResNet50, VGG16\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Conv2D, MaxPooling2D, Activation, Flatten, Dense, ZeroPadding2D, Dropout\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam, SGD\n",
        "from sklearn.metrics import classification_report\n",
        "from keras import models, optimizers\n",
        "from keras.callbacks import CSVLogger, ModelCheckpoint"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPzE9Zs-uJ61",
        "colab_type": "text"
      },
      "source": [
        "Mounting drive containing datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2L5Qf9sNlKDi",
        "colab_type": "code",
        "outputId": "fe09bfed-b0fb-4a75-9ec9-b494e642411c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "path_drive = '/content/gdrive/My Drive'\n",
        "\n",
        "import os\n",
        "os.chdir('/content/gdrive/My Drive/snr_unpacked/')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GO_IvPcKleOc",
        "colab_type": "text"
      },
      "source": [
        "VGG network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56bUh1_YlSo4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def VGG(img_height, img_width):\n",
        "  model = models.Sequential()\n",
        "  base_model = VGG16(include_top=False, input_shape=(img_height, img_width, 3), weights='imagenet')\n",
        "  base_model.summary()\n",
        "  for layer in base_model.layers:\n",
        "      layer.trainable = False\n",
        "  model.add(base_model)\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(units=1024,activation=\"relu\"))\n",
        "  model.add(Dense(units=512,activation=\"relu\"))\n",
        "  model.add(Dense(units=2, activation='softmax'))\n",
        "\n",
        "  for layer in model.layers[:8]:\n",
        "      layer.trainable=True\n",
        "\n",
        "  return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbBq-P5rlYXS",
        "colab_type": "text"
      },
      "source": [
        "LeNet network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svucMKzamHIR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def LeNet(img_height, img_width):\n",
        "\n",
        "    model = models.Sequential()\n",
        "\n",
        "    model.add(Conv2D(32, (3, 3), input_shape=(img_height, img_width, 3)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Conv2D(32, (3, 3)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Conv2D(64, (3, 3)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(units=512,activation=\"relu\"))\n",
        "    model.add(Dense(units=256,activation=\"relu\"))\n",
        "\n",
        "    model.add(Dense(1))\n",
        "    model.add(Activation('sigmoid'))\n",
        "\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbfVv48FWmq1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf \n",
        "def get_session(gpu_fraction=0.3):\n",
        "  num_threads = os.environ.get('OMP_NUM_THREADS')\n",
        "  gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=gpu_fraction)\n",
        "\n",
        "  if num_threads:\n",
        "      return tf.Session(config=tf.ConfigProto(\n",
        "          gpu_options=gpu_options, intra_op_parallelism_threads=num_threads))\n",
        "  else:\n",
        "      return tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
        "\n",
        "config = tf.ConfigProto( device_count = {'GPU': 1 , 'CPU': 8} )\n",
        "sess = tf.Session(config=config)\n",
        "keras.backend.set_session(get_session())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmC7_DKVvvkS",
        "colab_type": "text"
      },
      "source": [
        "Preparing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40-fNHcYlPdt",
        "colab_type": "code",
        "outputId": "19cb90c2-bf0a-4e50-b060-8014ec818c33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "source": [
        "image_shape = (776, 200)\n",
        "img_height = 200\n",
        "img_width = 776\n",
        "model = LeNet(img_height, img_width)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "in2xTJrYlX3y",
        "colab_type": "code",
        "outputId": "9e8c842e-42e0-4128-b874-4c86fc7a354f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=4,\n",
        "    # horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        'train',\n",
        "        target_size=(img_height, img_width),\n",
        "        batch_size=4)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        'test',\n",
        "        target_size=(img_height, img_width),\n",
        "        batch_size=4)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 646 images belonging to 2 classes.\n",
            "Found 162 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97qP_eAU9wr2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def noise_generator(batches):\n",
        "    \"\"\"Take as input a Keras ImageGen (Iterator) and generate random\n",
        "    crops from the image batches generated by the original iterator.\n",
        "    \"\"\"\n",
        "    import numpy as np\n",
        "    import cv2\n",
        "    while True:\n",
        "        batch_x, batch_y = next(batches)\n",
        "        batch_crops = np.zeros(batch_x.shape)\n",
        "        for i in range(batch_x.shape[0]):\n",
        "          if np.random.randint(0,1):\n",
        "            noise = np.random.normal(0, np.random.randint(0, 50)/ 255.0, batch_x[i].shape)\n",
        "            batch_crops[i] = batch_x[i]+noise\n",
        "          else:\n",
        "            batch_crops[i] = cv2.GaussianBlur(batch_x[i],(3,3),0)\n",
        "        yield (batch_crops, batch_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUeDh-KrlU4B",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdnnEpvolrDH",
        "colab_type": "code",
        "outputId": "ef7a5686-f81c-44a4-a4c6-f2a3b1a70f82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.compile(optimizer=Adam(0.0001), loss='categorical_crossentropy', metrics=['accuracy'])  # precision, recall and f1 are misleading for batch processing\n",
        "model.summary()\n",
        "save_dir = '/content/gdrive/My Drive/SNR/modele'\n",
        "save_every = 1\n",
        "checkpointer = ModelCheckpoint(os.path.join(save_dir, 'model_VGG{epoch:03d}.hdf5'), verbose=1, save_weights_only=False, period=save_every)\n",
        "\n",
        "csv_logger = CSVLogger(os.path.join(save_dir, 'log.csv'), append=True, separator=',')\n",
        "\n",
        "step_size_train=train_generator.n // train_generator.batch_size\n",
        "\n",
        "step_size_test = test_generator.n // train_generator.batch_size\n",
        "\n",
        "history = model.fit_generator(generator=noise_generator(train_generator),\n",
        "                   steps_per_epoch=step_size_train,\n",
        "                validation_data=test_generator,\n",
        "                validation_steps=step_size_test,\n",
        "                   epochs=20, callbacks=[checkpointer, csv_logger])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 198, 774, 32)      896       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 198, 774, 32)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 99, 387, 32)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 97, 385, 32)       9248      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 97, 385, 32)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 48, 192, 32)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 46, 190, 64)       18496     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 46, 190, 64)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 23, 95, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 139840)            0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               71598592  \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 257       \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 71,758,817\n",
            "Trainable params: 71,758,817\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-5ab480b79933>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep_size_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                    epochs=20, callbacks=[checkpointer, csv_logger])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1656\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1657\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1658\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    213\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    214\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1441\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1442\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m             class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1444\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    793\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    139\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected activation_4 to have shape (1,) but got array with shape (2,)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emiEcMXtlt6z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "model = load_model('/content/gdrive/My Drive/SNR/modele/model_VGG007.hdf5', compile=False)\n",
        "\n",
        "y_pred = model.predict_generator(test_generator, verbose=1)\n",
        "\n",
        "# y_pred_bool = np.argmax(y_pred, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2gM9J4PnCoP",
        "colab_type": "text"
      },
      "source": [
        "# Plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pP_Mw4DpvMal",
        "colab_type": "text"
      },
      "source": [
        "Classification report and confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yva306pDlw2Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, precision_recall_curve\n",
        "print(test_generator.classes)\n",
        "print(y_pred)\n",
        "y_class=[]\n",
        "for y in y_pred:\n",
        "  if y[0]>y[1]:\n",
        "    y_class.append(0)\n",
        "  else:\n",
        "    y_class.append(1)\n",
        "  print(y, y_class[-1])\n",
        "\n",
        "print(classification_report(test_generator.classes, np.around(y_class)))\n",
        "print(confusion_matrix(test_generator.classes, np.around(y_class)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8nQurOuvTHq",
        "colab_type": "text"
      },
      "source": [
        "Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sI4zq8Aushy8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zc6w9TrqvXhh",
        "colab_type": "text"
      },
      "source": [
        "Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbRiyvjcnAsI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.grid()\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2c33Pg1vZaC",
        "colab_type": "text"
      },
      "source": [
        "ROC and precision-recall"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Htz0WswmF--",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_class=[]\n",
        "for y in y_pred:\n",
        "  if y[0]>y[1]:\n",
        "    y_class.append(y[0])\n",
        "  else:\n",
        "    y_class.append(y[1])\n",
        "ns_fpr, ns_tpr, _ = roc_curve(test_generator.classes, y_class)\n",
        "plt.plot(ns_fpr, ns_tpr, linestyle='--')\n",
        "plt.grid()\n",
        "plt.show()\n",
        "precision, recall, thresholds = precision_recall_curve(test_generator.classes, y_class)\n",
        "plt.plot(recall, precision, marker='.')\n",
        "plt.grid()\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}